{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your dataset class and transformations\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path, class_names, transform=None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.class_names = class_names\n",
    "        self.transform = transform\n",
    "        self.data = self.load_dataset()\n",
    "\n",
    "    def load_dataset(self):\n",
    "        data = []\n",
    "        for idx, class_name in enumerate(self.class_names):\n",
    "            class_path = os.path.join(self.dataset_path, class_name)\n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                label = idx  # Numerical label based on class index\n",
    "                data.append((image_path, label))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and class names\n",
    "train_dataset_path = \"../dataset/train/\"\n",
    "test_dataset_path = \"../dataset/test/\"\n",
    "class_names = [\"Black Rot\", \"ESCA\", \"Healthy\", \"Leaf Blight\"]\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    # Add other transformations as needed\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset instances\n",
    "train_dataset = CustomDataset(\n",
    "    train_dataset_path, class_names, transform=transform)\n",
    "test_dataset = CustomDataset(\n",
    "    test_dataset_path, class_names, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Faster R-CNN model\n",
    "backbone = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "    pretrained=True)\n",
    "backbone.out_channels = 256  # Adjust the number of output channels\n",
    "rpn_anchor_generator = AnchorGenerator(\n",
    "    sizes=((32, 64, 128, 256, 512),),\n",
    "    aspect_ratios=((0.5, 1.0, 2.0),) * 5\n",
    ")\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "    featmap_names=['0'], output_size=7, sampling_ratio=2\n",
    ")\n",
    "model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=len(class_names),\n",
    "    rpn_anchor_generator=rpn_anchor_generator,\n",
    "    box_roi_pool=roi_pooler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "model.eval()\n",
    "image_path = \"path_to_your_image.jpg\"  # Replace with your image path\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(image_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process prediction for visualization\n",
    "def visualize_prediction(image, predictions, class_names):\n",
    "    boxes = predictions[0]['boxes'].detach().cpu().numpy()\n",
    "    labels = predictions[0]['labels'].detach().cpu().numpy()\n",
    "    scores = predictions[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, len(class_names))).tolist()\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        box = [int(b) for b in box]\n",
    "        color = colors[label]\n",
    "        label_text = f\"{class_names[label]}: {score:.2f}\"\n",
    "        ax.add_patch(plt.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1],\n",
    "                                   fill=False, edgecolor=color, linewidth=2))\n",
    "        ax.text(box[0], box[1], label_text,\n",
    "                bbox=dict(facecolor=color, alpha=0.5))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "visualize_prediction(image, predictions, class_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
