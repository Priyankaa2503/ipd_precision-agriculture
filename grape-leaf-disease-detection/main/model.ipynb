{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"../dataset/train/\"\n",
    "test_dataset_path = \"../dataset/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 4 classes.\n",
      "Found 1805 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Black Rot\", \"ESCA\", \"Healthy\", \"Leaf Blight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(class_names), activation=\"softmax\"))\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_model(Adam(learning_rate=0.001))\n",
    "model2 = create_model(Adam(learning_rate=0.0001))\n",
    "model3 = create_model(SGD(learning_rate=0.01, momentum=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.7782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 733s 2s/step - loss: 0.5890 - accuracy: 0.7782 - val_loss: 0.1865 - val_accuracy: 0.9286\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 497s 1s/step - loss: 0.1951 - accuracy: 0.9327 - val_loss: 0.1844 - val_accuracy: 0.9369\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 482s 1s/step - loss: 0.1181 - accuracy: 0.9588 - val_loss: 0.1321 - val_accuracy: 0.9587\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 470s 1s/step - loss: 0.0585 - accuracy: 0.9806 - val_loss: 0.0927 - val_accuracy: 0.9715\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 490s 1s/step - loss: 0.0435 - accuracy: 0.9858 - val_loss: 0.1700 - val_accuracy: 0.9369\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 494s 1s/step - loss: 0.0396 - accuracy: 0.9863 - val_loss: 0.1126 - val_accuracy: 0.9721\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 560s 1s/step - loss: 0.0369 - accuracy: 0.9890 - val_loss: 0.1070 - val_accuracy: 0.9732\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 553s 1s/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.1512 - val_accuracy: 0.9559\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 666s 2s/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0974 - val_accuracy: 0.9760\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 619s 2s/step - loss: 0.0346 - accuracy: 0.9879 - val_loss: 0.0804 - val_accuracy: 0.9760\n",
      "Training model 2\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 552s 1s/step - loss: 0.7038 - accuracy: 0.7153 - val_loss: 0.3171 - val_accuracy: 0.8901\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 613s 2s/step - loss: 0.3621 - accuracy: 0.8670 - val_loss: 0.2416 - val_accuracy: 0.9191\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 657s 2s/step - loss: 0.2798 - accuracy: 0.8971 - val_loss: 0.1692 - val_accuracy: 0.9358\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 530s 1s/step - loss: 0.2345 - accuracy: 0.9125 - val_loss: 0.1448 - val_accuracy: 0.9414\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 495s 1s/step - loss: 0.2095 - accuracy: 0.9205 - val_loss: 0.1520 - val_accuracy: 0.9431\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 515s 1s/step - loss: 0.1847 - accuracy: 0.9318 - val_loss: 0.1247 - val_accuracy: 0.9520\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 480s 1s/step - loss: 0.1660 - accuracy: 0.9387 - val_loss: 0.1355 - val_accuracy: 0.9503\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 490s 1s/step - loss: 0.1434 - accuracy: 0.9475 - val_loss: 0.0965 - val_accuracy: 0.9593\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 468s 1s/step - loss: 0.1383 - accuracy: 0.9491 - val_loss: 0.1325 - val_accuracy: 0.9498\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 516s 1s/step - loss: 0.1282 - accuracy: 0.9533 - val_loss: 0.1053 - val_accuracy: 0.9570\n",
      "Training model 3\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 429s 1s/step - loss: 0.9033 - accuracy: 0.6143 - val_loss: 0.4825 - val_accuracy: 0.7930\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 424s 1s/step - loss: 0.3798 - accuracy: 0.8514 - val_loss: 0.1781 - val_accuracy: 0.9325\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 429s 1s/step - loss: 0.2039 - accuracy: 0.9241 - val_loss: 0.1905 - val_accuracy: 0.9269\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 430s 1s/step - loss: 0.1638 - accuracy: 0.9402 - val_loss: 0.1365 - val_accuracy: 0.9509\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 437s 1s/step - loss: 0.1186 - accuracy: 0.9584 - val_loss: 0.1239 - val_accuracy: 0.9542\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 434s 1s/step - loss: 0.0911 - accuracy: 0.9685 - val_loss: 0.1169 - val_accuracy: 0.9576\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 440s 1s/step - loss: 0.0791 - accuracy: 0.9742 - val_loss: 0.1230 - val_accuracy: 0.9581\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 458s 1s/step - loss: 0.0681 - accuracy: 0.9776 - val_loss: 0.1219 - val_accuracy: 0.9615\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 429s 1s/step - loss: 0.0759 - accuracy: 0.9733 - val_loss: 0.1074 - val_accuracy: 0.9654\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 420s 1s/step - loss: 0.0778 - accuracy: 0.9764 - val_loss: 0.1038 - val_accuracy: 0.9676\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate([model1, model2, model3], start=1):\n",
    "    print(f\"Training model {i}\")\n",
    "    checkpoint = ModelCheckpoint(f\"model{i}.h5\", save_best_only=True)\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=test_generator.samples // test_generator.batch_size,\n",
    "        callbacks=[checkpoint],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions(models, testX):\n",
    "    results = [model.predict(testX) for model in models]\n",
    "    results = np.array(results)\n",
    "    summed = np.sum(results, axis=0)\n",
    "    return np.argmax(summed, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred = ensemble_predictions(models, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 100.000\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(ensemble_pred == np.argmax(testY, axis=1))\n",
    "print('Ensemble Accuracy: %.3f' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../black_rot_test.png\"\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002518C4D71A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002518C52F740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Predicted class: Black Rot\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred = ensemble_predictions(models, img)\n",
    "\n",
    "predicted_class = class_names[ensemble_pred[0]]\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
